{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData():\n",
    "    from sklearn import datasets\n",
    "    dataset = datasets.fetch_california_housing(as_frame = True)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import numpy as np\n",
    "    np.random.seed(1)\n",
    "\n",
    "    dataset.frame_normalized = StandardScaler().fit_transform(dataset.frame)\n",
    "    # We drop Longitude as well since Latitude has enough information\n",
    "    X = dataset.frame_normalized[:,0:len(dataset.frame.columns) - 2]\n",
    "    y = dataset.frame_normalized[:,len(dataset.frame.columns) - 1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 9)\n",
    "    X_train = np.insert(X_train, 0, np.ones(X_train.shape[0]), axis=1)\n",
    "    X_test = np.insert(X_test, 0, np.ones(X_test.shape[0]), axis=1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dot(W, x):\n",
    "    value = np.dot(W, x)\n",
    "\n",
    "    def vjp(u):\n",
    "        vjp_wrt_W = np.outer(u, x)  #applied to W\n",
    "        vjp_wrt_x = W.T.dot(u)  #applied to x\n",
    "        return vjp_wrt_x, vjp_wrt_W\n",
    "        \n",
    "    return value, vjp\n",
    "\n",
    "def relu(x):\n",
    "    value = np.maximum(0, x)\n",
    "\n",
    "    def vjp(u):\n",
    "        gdash = lambda y: 1 if y>=0 else 0\n",
    "        vjp_wrt_x = u*np.vectorize(gdash)(x)\n",
    "        return vjp_wrt_x,  \n",
    "        # The comma is important!\n",
    "    \n",
    "    return value, vjp\n",
    "\n",
    "def initialiseMLP_random(inputfeatures, layers, unif=False, verbose=False):\n",
    "    dims = np.random.choice([i for i in range(2,8)], layers)\n",
    "    if unif:\n",
    "        W = [np.random.uniform(-1, 1, size=(dims[0], inputfeatures))]\n",
    "    else:\n",
    "        W = [np.array(np.random.rand(dims[0], inputfeatures))]\n",
    "    for i in range(1, len(dims)):\n",
    "        if unif:\n",
    "            Wi = np.random.uniform(-1, 1, size=(dims[i], dims[i-1]))\n",
    "        else:\n",
    "            Wi = np.array(np.random.rand(dims[i], dims[i-1]))\n",
    "        W.append(Wi)\n",
    "\n",
    "    W.reverse()\n",
    "    if unif:\n",
    "        x = np.random.uniform(-1, 1, inputfeatures)\n",
    "        u = np.random.uniform(-1, 1, dims[-1])\n",
    "    else:\n",
    "        x = np.random.uniform(0, 1, inputfeatures)\n",
    "        u = np.random.uniform(0, 1, dims[-1])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"u=\", np.shape(u))\n",
    "        for i in range(len(W)):\n",
    "            print(\"W{i}=\".format(i=i), np.shape(W[i]))\n",
    "        print(\"x=\", np.shape(x))\n",
    "\n",
    "    return x, W, u\n",
    "\n",
    "def mlp2(x, W):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        x = input data\n",
    "        W = list of weight matrices, W = [Wk, ..., W3, W2, W1]\n",
    "    formula:\n",
    "        y = W2.q(W1.x)\n",
    "    returns:\n",
    "        value = evaluated value according to formula\n",
    "        vjp = tuple of vjp's in order x, W\n",
    "    \"\"\"\n",
    "    W2, W1 = W\n",
    "    a, vjp_dot1 = dot(W1, x)\n",
    "    b, vjp_relu = relu(a)\n",
    "    c, vjp_dot2 = dot(W2, b)\n",
    "    value = c\n",
    "\n",
    "    def vjp(u):\n",
    "        vjp_wrt_b, vjp_wrt_W2 = vjp_dot2(u)\n",
    "        vjp_wrt_a, = vjp_relu(vjp_wrt_b)\n",
    "        vjp_wrt_x, vjp_wrt_W1 = vjp_dot1(vjp_wrt_a) \n",
    "\n",
    "        return vjp_wrt_x, [vjp_wrt_W2, vjp_wrt_W1]\n",
    "    return value, vjp\n",
    "\n",
    "def mlpk(x, W): #W = [Wk, ..., W3, W2, W1]\n",
    "    if (len(W)>=3):\n",
    "        value, vjp_1 = mlpk(x, W[1:len(W)])\n",
    "    else:\n",
    "        # value, vjp_1 = mlp2(x, [W[-2], W[-1]]) 04/01 change to:\n",
    "        return mlp2(x, [W[-2], W[-1]])\n",
    "    \n",
    "    value, vjp_2 = relu(value)\n",
    "    value, vjp_3 = dot(W[0], value)\n",
    "\n",
    "    def vjp(u):\n",
    "        vjp_wrt_x, vjp_wrt_Wk = vjp_3(u)\n",
    "        vjp_wrt_x, = vjp_2(vjp_wrt_x)\n",
    "        # vjp_wrt_x_wrtW = vjp_1(vjp_wrt_x) 04/01 change to:\n",
    "        vjp_wrt_x, *vjp_wrt_W = vjp_1(vjp_wrt_x)\n",
    "        #04/01 add:\n",
    "        vjp_wrt_W = vjp_wrt_W[0]\n",
    "        vjp_wrt_W.append(vjp_wrt_Wk)\n",
    "        return vjp_wrt_x, vjp_wrt_W\n",
    "        # return vjp_wrt_x_wrtW, vjp_wrt_Wk 04/01 comment out\n",
    "\n",
    "    return value, vjp\n",
    "\n",
    "def squared_loss(y_pred, y):\n",
    "    residual = y_pred - y\n",
    "    \n",
    "    def vjp(u):\n",
    "        vjp_y_pred = u*(1*residual)\n",
    "        vjp_y = u*(-1*residual)\n",
    "        return vjp_y_pred, vjp_y\n",
    "\n",
    "    value = 0.5 * np.sum(residual ** 2)\n",
    "    # The code requires every output to be an array.\n",
    "    return value, vjp\n",
    "    # return np.array([value]), vjp\n",
    "\n",
    "def loss_i(i, X, y, W):\n",
    "    x = X[i] # np.reshape(X[i], (X.shape[1],))\n",
    "    pred_value, predicted_vjp = mlpk(x, W)\n",
    "    loss_value, loss_vjp = squared_loss(pred_value, y[i])\n",
    "    value = loss_value\n",
    "\n",
    "    def vjp(u):\n",
    "        vjp_y, vjp_y_pred = loss_vjp(u)\n",
    "        vjp_x, vjp_W = predicted_vjp(vjp_y_pred)\n",
    "        return vjp_x, vjp_y, vjp_W\n",
    "    \n",
    "    return value, vjp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = importData()\n",
    "n, d = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(niter, step, W):\n",
    "    n, d = X_train.shape\n",
    "    loss_evol = []\n",
    "\n",
    "    for it in range(niter):\n",
    "        i = np.random.choice(n, 1)[-1]\n",
    "\n",
    "        vali, vjpi = loss_i(i, X_train, y_train, W)\n",
    "        vjp_wrtx, vjp_wrty, vjp_wrtW = vjpi(1)\n",
    "\n",
    "        for k in range(len(W)):\n",
    "            print(W[k].shape, vjp_wrtW[k].shape, i, step)\n",
    "            W[k] = W[k] - vjp_wrtW[k]*step\n",
    "    \n",
    "        loss_evol.append(vali)\n",
    "\n",
    "    return loss_evol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5) (1, 5) 12172 0.05\n",
      "(5, 8) (5, 8) 12172 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[49.92143895046307]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0 = np.ones((5, d))\n",
    "W1 = np.ones((5, 5))\n",
    "W2 = np.ones((1, 5))\n",
    "W = [W2, W0]\n",
    "\n",
    "# for i in W: print(i.shape)\n",
    "SGD(niter=1, step=0.05, W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfa605650d3342199cd8cd9bb236e9172d9224cad72c2719efab3fb60e30b42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
